{"cells":[{"metadata":{},"cell_type":"markdown","source":"# Watch the input files"},{"metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\n\ndef show_input_dir():\n    for dirname, _, filenames in os.walk('../input'):\n        for filename in filenames:\n            print(os.path.join(dirname, filename))\n\nshow_input_dir()\n\n# Any results you write to the current directory are saved as output.","execution_count":145,"outputs":[{"output_type":"stream","text":"../input/digit-recognizer/test.csv\n../input/digit-recognizer/train.csv\n../input/digit-recognizer/sample_submission.csv\n","name":"stdout"}]},{"metadata":{},"cell_type":"markdown","source":"# Import required libraries"},{"metadata":{"trusted":true},"cell_type":"code","source":"import pandas as pd","execution_count":146,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import torch\nimport torch.nn as nn\nimport torch.optim as optim\nfrom torch.utils.data import DataLoader, TensorDataset\nfrom torch.utils.data import sampler\nimport torch.nn.functional as F","execution_count":147,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import matplotlib.pyplot as plt\n\n%matplotlib inline","execution_count":148,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Declare common parameters"},{"metadata":{"trusted":true},"cell_type":"code","source":"image_shape = (1, 28, 28)\ndtype = torch.cuda.FloatTensor\nbatch_size = 100","execution_count":149,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Declare all the functions we need"},{"metadata":{},"cell_type":"markdown","source":"## Reading the data, sampling, data loaders"},{"metadata":{"_cell_guid":"","_uuid":"","trusted":true},"cell_type":"code","source":"\ndef read_input_data():\n    sample_submission = pd.read_csv(\"../input/digit-recognizer/sample_submission.csv\")\n    test = pd.read_csv(\"../input/digit-recognizer/test.csv\")\n    train = pd.read_csv(\"../input/digit-recognizer/train.csv\")\n    return train, test","execution_count":150,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"class ChunkSampler(sampler.Sampler):\n    def __init__(self, samples_count, offset=0):\n        self.samples_count = samples_count\n        self.offset = offset\n\n    def __iter__(self):\n        return iter(range(self.offset, self.offset + self.samples_count))\n\n    def __len__(self):\n        return self.samples_count","execution_count":151,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def get_loader(data, num_values, batch_size=batch_size, start=0):\n    labels = data['label'].values\n    images = data.drop('label',axis=1).values\n\n    images_tensor = torch.tensor(images / 255)\n    labels_tensor = torch.tensor(labels)\n    tensor_dataset = TensorDataset(images_tensor, labels_tensor)\n\n    loader = DataLoader(tensor_dataset, batch_size=batch_size,\n                              sampler=ChunkSampler(num_values, start))\n    return loader","execution_count":152,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def get_test_loader(data, num_values, batch_size=batch_size, start=0):\n    images = data.values\n\n    images_tensor = torch.tensor(images / 255)\n    tensor_dataset = TensorDataset(images_tensor)\n\n    loader = DataLoader(tensor_dataset, batch_size=batch_size,\n                              sampler=ChunkSampler(num_values, start))\n    return loader","execution_count":153,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Declare custom layers to make the data flatten and unflatten"},{"metadata":{"trusted":true},"cell_type":"code","source":"class Flatten(nn.Module):\n    def forward(self, x):\n        N, C, H, W = x.size()\n        return x.view(N, -1)\n    \nclass Unflatten(nn.Module):\n    def __init__(self, N=-1, C=128, H=7, W=7):\n        super(Unflatten, self).__init__()\n        self.N = N\n        self.C = C\n        self.H = H\n        self.W = W\n    def forward(self, x):\n        return x.view(self.N, self.C, self.H, self.W)","execution_count":154,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Define network model"},{"metadata":{"trusted":true},"cell_type":"code","source":"class Alex(nn.Module):\n    def __init__(self, image_shape):\n        super(Alex, self).__init__()\n        self.unflat = Unflatten(-1, *image_shape)\n        self.conv1 = nn.Conv2d(1, 64, kernel_size=11, stride=4, padding=2)\n        self.relu1 = nn.ReLU(inplace=True)\n        self.mp1 = nn.MaxPool2d(kernel_size=1)\n        self.conv2 = nn.Conv2d(64, 192, kernel_size=5, padding=2)\n        self.relu2 = nn.ReLU(inplace=True)\n        self.mp2 = nn.MaxPool2d(kernel_size=5, stride=2)\n        self.conv3 = nn.Conv2d(192, 384, kernel_size=3, padding=1)\n        self.relu4 = nn.ReLU(inplace=True)\n        self.conv4 = nn.Conv2d(384, 256, kernel_size=3, padding=1)\n        self.relu4 = nn.ReLU(inplace=True)\n        self.conv5 = nn.Conv2d(256, 256, kernel_size=3, padding=1)\n        self.relu5 = nn.ReLU(inplace=True)\n        self.mp3 = nn.MaxPool2d(kernel_size=1)\n        self.flat = Flatten()\n        self.do1 = nn.Dropout()\n        self.lin1 = nn.Linear(256, 4069)\n        self.relu6 = nn.ReLU(inplace=True)\n        self.do2 = nn.Dropout()\n        self.lin2 = nn.Linear(4069, 4069)\n        self.relu7 = nn.ReLU(inplace=True)\n        self.lin3 = nn.Linear(4069, 10)\n    def forward(self, x):\n        x = self.unflat(x)\n        x = self.conv1(x)\n        x = self.relu1(x)\n        x = self.mp1(x)\n        x = self.conv2(x)\n        x = self.relu2(x)\n        x = self.mp2(x)\n        x = self.conv3(x)\n        x = self.relu4(x)\n        x = self.conv4(x)\n        x = self.relu4(x)\n        x = self.conv5(x)\n        x = self.relu5(x)\n        x = self.mp3(x)\n        x = self.flat(x)\n        x = self.do1(x)\n        x = self.lin1(x)\n        x = self.relu6(x)\n        x = self.do2(x)\n        x = self.lin2(x)\n        x = self.relu7(x)\n        x = self.lin3(x)\n        return x","execution_count":155,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Declare functions to calculate accuracy and loss"},{"metadata":{"trusted":true},"cell_type":"code","source":"def evaluate_accuracy(predicted, labels):\n    correct = (predicted == labels).sum().item()\n    accuracy = correct / len(labels)\n    \n    return accuracy, correct","execution_count":156,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def evaluate_loss(criterion, outputs, labels):\n    loss = criterion(outputs, labels)\n    value = loss.data.item()\n    \n    return value, loss\n    ","execution_count":157,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Declare MetricCalculator"},{"metadata":{},"cell_type":"markdown","source":"MetricCalculator calculates any metric (accuracy, loss, etc) over the epochs."},{"metadata":{"trusted":true},"cell_type":"code","source":"class MetricCalculator:\n    def __init__(self):\n        self.data = []\n        self.cache = 0\n        self.batches_count = 0\n    def add_batch(self, item):\n        self.cache += item\n        self.batches_count += 1\n    def get_current(self):\n        return self.cache / self.batches_count\n    def submit(self):\n        self.data.append(self.get_current())\n        self.cache = 0\n        self.batches_count = 0\n    def average(self):\n        return np.sum(self.data)/ len(self.data)\n    def get(self):\n        return self.data","execution_count":158,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Predict only one batch."},{"metadata":{"trusted":true},"cell_type":"code","source":"def predict_batch(model, images):\n    batch = images.type(dtype)\n    outputs = model(batch).type(dtype)\n    _, predicted = torch.max(outputs.data, 1)\n    \n    return predicted, outputs","execution_count":159,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Make predictions for all the data."},{"metadata":{"trusted":true},"cell_type":"code","source":"def predict(model, loader):\n    result = []\n    for images, in loader:\n        predicted, _ = predict_batch(model, images)\n        result.extend(predicted.cpu().detach().numpy())\n    \n    return result\n    ","execution_count":160,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Learn network and calculate metrics. \"learn\" flag lets us not to learn network if we need to validate network only."},{"metadata":{"trusted":true},"cell_type":"code","source":"def run_cnn(model, optimizer, criterion, loader, batch_size=batch_size, print_each=250, num_epochs=10, learn=True):\n    if learn:\n        model.train()\n    else:\n        model.eval()\n    \n    batches_count = len(loader.sampler) // batch_size\n    loss_calculator = MetricCalculator()\n    accuracy_calculator = MetricCalculator()\n    for epoch in range(num_epochs):\n        iteration = 0\n        for images, labels in loader:\n            labels = labels.type(torch.cuda.LongTensor)\n            \n            if learn:\n                optimizer.zero_grad()\n                \n            predicted, outputs = predict_batch(model, images)\n            accuracy, _ = evaluate_accuracy(predicted, labels)\n            loss_value, loss = evaluate_loss(criterion, outputs, labels)\n            \n            accuracy_calculator.add_batch(accuracy)\n            loss_calculator.add_batch(loss_value)\n\n            if learn:\n                loss.backward()\n                optimizer.step()\n            \n            iteration += 1\n            \n            if iteration % print_each == 0:\n                print ('Epoch [%d/%d], Iter [%d/%d] Loss: %.4f,  Accuracy: %.4f,' %(epoch+1, num_epochs, iteration+1, len(loader.sampler)//batch_size, loss_calculator.get_current(), accuracy_calculator.get_current()))\n        accuracy_calculator.submit()\n        loss_calculator.submit()\n        \n    return loss_calculator.get(), accuracy_calculator.get()\n                ","execution_count":161,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Define PlotBuilder, that lets us quickly generate plots."},{"metadata":{"trusted":true},"cell_type":"code","source":"class PlotBuilder:\n    def __init__(self, xlabel='Epoch', ylabel='Loss'):\n        plt.xlabel(xlabel)\n        plt.ylabel(ylabel)\n    def add_line(self, values, label, color='r'):\n        plt.plot(range(len(values)), values, color, label=label)\n        return self\n    def title(self, title):\n        plt.title(title)\n        return self\n    def legend(self):\n        plt.legend()\n        return self\n    def show(self):\n        plt.show()","execution_count":162,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Make submission for the predictions."},{"metadata":{"trusted":true},"cell_type":"code","source":"def make_submission(predictions, filename=\"my_submissions.csv\"):\n    submissions=pd.DataFrame({\"ImageId\": list(range(1,len(predictions)+1)),\n                         \"Label\": predictions})\n    submissions.to_csv(filename, index=False, header=True)","execution_count":163,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# All the work"},{"metadata":{},"cell_type":"markdown","source":"Read the data."},{"metadata":{"trusted":true},"cell_type":"code","source":"train, test = read_input_data()","execution_count":164,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Define train and validation datasets sizes."},{"metadata":{"trusted":true},"cell_type":"code","source":"train_num = 30000\nvalidation_num = int(len(train) - train_num)\nprint('Train items count', train_num)\nprint('Validation items count', validation_num)","execution_count":165,"outputs":[{"output_type":"stream","text":"Train items count 30000\nValidation items count 12000\n","name":"stdout"}]},{"metadata":{},"cell_type":"markdown","source":"Define dataloaders."},{"metadata":{"trusted":true},"cell_type":"code","source":"train_loader = get_loader(train, train_num)\nvalidation_loader = get_loader(train, validation_num, start=train_num)\ntest_loader = get_test_loader(test, len(test))","execution_count":166,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Define the model and make it use GPU."},{"metadata":{"trusted":true},"cell_type":"code","source":"model = Alex(image_shape)\nmodel.cuda()","execution_count":167,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Define optimizer."},{"metadata":{"trusted":true},"cell_type":"code","source":"optimizer = optim.Adam(model.parameters(), lr=1e-3, betas=(0.5, 0.999))","execution_count":168,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Define loss."},{"metadata":{"trusted":true},"cell_type":"code","source":"criterion = nn.CrossEntropyLoss().cuda()","execution_count":169,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Define number of epochs."},{"metadata":{"trusted":true},"cell_type":"code","source":"num_epochs=12","execution_count":170,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Train the network."},{"metadata":{"trusted":true},"cell_type":"code","source":"train_loss, train_accuracy = run_cnn(model, optimizer, criterion, train_loader, num_epochs=num_epochs)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Validate the network."},{"metadata":{"trusted":true},"cell_type":"code","source":"validation_loss, validation_accuracy = run_cnn(model, optimizer, criterion, validation_loader, learn=False, num_epochs=num_epochs)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Generate plot to see validation and train accuracy and loss."},{"metadata":{"trusted":true},"cell_type":"code","source":"PlotBuilder().legend().add_line(train_loss, 'Train Loss', color='r').add_line(validation_loss, 'Validation Loss', color='b').show()\nPlotBuilder(ylabel='Accuracy').legend().add_line(train_accuracy, 'Train Accauracy', color='r').add_line(validation_accuracy, 'Validation Accauracy', color='b').show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Train network more with validations dataset."},{"metadata":{"trusted":true},"cell_type":"code","source":"run_cnn(model, optimizer, criterion, validation_loader, learn=True, num_epochs=num_epochs)\npass","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Make predictions for the test dataset."},{"metadata":{"trusted":true},"cell_type":"code","source":"predictions = predict(model, test_loader)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"make_submission(predictions)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.8"}},"nbformat":4,"nbformat_minor":1}